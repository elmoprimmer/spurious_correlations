{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-16T09:15:57.102408100Z",
     "start_time": "2025-05-16T09:15:51.177987500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from vit_wdpruning import VisionTransformerWithWDPruning\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elmop\\AppData\\Local\\Temp\\ipykernel_20832\\3054412544.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(\"logs/cifar10_small/checkpoint-best.pth\", map_location=torch.device('cpu'))[\"model\"]\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(\"logs/cifar10_small/checkpoint-best.pth\", map_location=torch.device('cpu'))[\"model\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-16T09:19:11.199983400Z",
     "start_time": "2025-05-16T09:19:10.906634600Z"
    }
   },
   "id": "58f37df0ac8f4363",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using stride: 16, and patch number is num_y14 * num_x14\n",
      "using drop_out rate is : 0.0\n",
      "using attn_drop_out rate is : 0.0\n",
      "using drop_path rate is : 0.1\n"
     ]
    }
   ],
   "source": [
    "model = VisionTransformerWithWDPruning(num_classes=10,\n",
    "                                       patch_size=16, embed_dim=384,\n",
    "                                       depth=12, num_heads=6, mlp_ratio=4,\n",
    "                                       head_pruning=True, fc_pruning=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-16T09:32:59.344970700Z",
     "start_time": "2025-05-16T09:32:58.986857600Z"
    }
   },
   "id": "70680479d1c619be",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "_IncompatibleKeys(missing_keys=[], unexpected_keys=['norm_classifier.2.weight', 'norm_classifier.2.bias', 'head_classifier.2.weight', 'head_classifier.2.bias'])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(ckpt, strict=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-16T09:33:01.252741600Z",
     "start_time": "2025-05-16T09:33:01.171701Z"
    }
   },
   "id": "e2e25b653b7928d",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([11.7130], requires_grad=True)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[0].attn.proj.threshold_fc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-16T09:44:23.666513500Z",
     "start_time": "2025-05-16T09:44:23.590967900Z"
    }
   },
   "id": "bade8856fe6993e8",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "21706518"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count(m): return sum(p.numel() for p in m.parameters())\n",
    "count(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-16T09:21:26.609519500Z",
     "start_time": "2025-05-16T09:21:26.477762400Z"
    }
   },
   "id": "dfbc11fd95165edc",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sigmoid(): argument 'input' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_structural_pruning\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m count(model)\n",
      "File \u001B[1;32m~\\deep_feature_reweighting\\deep_feature_reweighting\\external\\wdpruning\\vit_wdpruning.py:401\u001B[0m, in \u001B[0;36mVisionTransformerWithWDPruning._make_structural_pruning\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_make_structural_pruning\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks)):\n\u001B[1;32m--> 401\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblocks\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlayer\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_structural_pruning\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\deep_feature_reweighting\\deep_feature_reweighting\\external\\wdpruning\\vit_wdpruning.py:200\u001B[0m, in \u001B[0;36mBlock.make_structural_pruning\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake_structural_pruning\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 200\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_structural_pruning\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;66;03m# make self.intermediate and self.output to be structural prune\u001B[39;00m\n\u001B[0;32m    202\u001B[0m     intermediate_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp\u001B[38;5;241m.\u001B[39mfc1\u001B[38;5;241m.\u001B[39mmake_inference_pruning()  \u001B[38;5;66;03m# we need this to do the residual connection\u001B[39;00m\n",
      "File \u001B[1;32m~\\deep_feature_reweighting\\deep_feature_reweighting\\external\\wdpruning\\vit_wdpruning.py:144\u001B[0m, in \u001B[0;36mAttention.make_structural_pruning\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake_structural_pruning\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;66;03m# make the structural pruning here for attention for inference\u001B[39;00m\n\u001B[1;32m--> 144\u001B[0m     value_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mqkv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_inference_pruning\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    145\u001B[0m     num_head \u001B[38;5;241m=\u001B[39m (value_mask\u001B[38;5;241m.\u001B[39msum() \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m64\u001B[39m)\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(num_head)\n",
      "File \u001B[1;32m~\\deep_feature_reweighting\\deep_feature_reweighting\\external\\wdpruning\\pruner\\modules\\masked_linear.py:90\u001B[0m, in \u001B[0;36mMaskedLinear.make_inference_pruning\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake_inference_pruning\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minference_mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 90\u001B[0m     mask_head, mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     91\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_pruning:\n\u001B[0;32m     92\u001B[0m         mask_head \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones_like(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight[:, \u001B[38;5;241m0\u001B[39m])\u001B[38;5;241m.\u001B[39mtype(\n\u001B[0;32m     93\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtorch.BoolTensor\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\deep_feature_reweighting\\deep_feature_reweighting\\external\\wdpruning\\pruner\\modules\\masked_linear.py:75\u001B[0m, in \u001B[0;36mMaskedLinear.get_mask\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_mask\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     73\u001B[0m     \u001B[38;5;66;03m# get head mask\u001B[39;00m\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_pruning:\n\u001B[1;32m---> 75\u001B[0m         mask_head \u001B[38;5;241m=\u001B[39m \u001B[43mTopKBinarizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhead_saliency_scores\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthreshold_head\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# for now, only support this\u001B[39;00m\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     78\u001B[0m         mask_head \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dfr\\lib\\site-packages\\torch\\autograd\\function.py:574\u001B[0m, in \u001B[0;36mFunction.apply\u001B[1;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_are_functorch_transforms_active():\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001B[39;00m\n\u001B[0;32m    573\u001B[0m     args \u001B[38;5;241m=\u001B[39m _functorch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39munwrap_dead_wrappers(args)\n\u001B[1;32m--> 574\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m    576\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_setup_ctx_defined:\n\u001B[0;32m    577\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    578\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn order to use an autograd.Function with functorch transforms \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    579\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    580\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstaticmethod. For more details, please see \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    581\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    582\u001B[0m     )\n",
      "File \u001B[1;32m~\\deep_feature_reweighting\\deep_feature_reweighting\\external\\wdpruning\\pruner\\modules\\binarizer.py:14\u001B[0m, in \u001B[0;36mTopKBinarizer.forward\u001B[1;34m(ctx, inputs, threshold, head_split)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(ctx, inputs: torch\u001B[38;5;241m.\u001B[39mtensor, threshold: \u001B[38;5;28mfloat\u001B[39m, head_split: \u001B[38;5;28mint\u001B[39m):\n\u001B[0;32m     11\u001B[0m \n\u001B[0;32m     12\u001B[0m     \u001B[38;5;66;03m# Get the subnetwork by sorting the inputs and using the top threshold\u001B[39;00m\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;66;03m# %\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m     threshold \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msigmoid\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthreshold\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     16\u001B[0m     mask \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mclone()\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m head_split \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "\u001B[1;31mTypeError\u001B[0m: sigmoid(): argument 'input' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "model._make_structural_pruning()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-16T09:21:56.456751400Z",
     "start_time": "2025-05-16T09:21:55.448566600Z"
    }
   },
   "id": "6eb29f116fec8561",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "15469134"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-16T09:22:03.901766Z",
     "start_time": "2025-05-16T09:22:03.876800100Z"
    }
   },
   "id": "18891ea8dab6f5de",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.7126492604663723"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15469134/21706518"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-16T09:22:31.666733200Z",
     "start_time": "2025-05-16T09:22:31.578507700Z"
    }
   },
   "id": "c13238cdb39a8cd8",
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
