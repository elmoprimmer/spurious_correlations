load the dataset
waterbirds
get train set
[0 1 2 3]
Number of unique labels: 2, Number of unique places: 2, Total groups: 4
group 0: 3518
group 1: 185
group 2: 55
group 3: 1037
get valid set
[0 1 2 3]
Number of unique labels: 2, Number of unique places: 2, Total groups: 4
group 0: 456
group 1: 456
group 2: 143
group 3: 144
get test set
[0 1 2 3]
Number of unique labels: 2, Number of unique places: 2, Total groups: 4
group 0: 2255
group 1: 2255
group 2: 642
group 3: 642
0
1
2
3
pruning indices  400
0
1
2
3
pruning indices (val) 160
Arch:vit_b_16
pruning_rates
[0, 0.01, 0.05, 0.1, 0.2, 0.3]
one hot
/home/primmere/.conda/envs/dfr2/lib/python3.10/site-packages/torch/autograd/graph.py:768: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
one hot
Initial accuracy (val set): top1=0.34225060407317914
Initial worst accuracy (val set)=0.23902439024390243
Initial group accuracies (val set)={3: 0.4797507788161994, 2: 0.5124610591900312, 1: 0.3578713968957871, 0: 0.23902439024390243}
Computing accuracy for model pruned with 30%:  83%|████████▎ | 5/6 [03:15<00:39, 39.38s/it]
acc top1 (train) 0.39
group accs (train) {2: 0.48, 3: 0.49, 0: 0.25, 1: 0.34}
Accuracy-Flow list (val): [0.34225060407317914]
Group accuracy (val): {3: 0.4797507788161994, 2: 0.5124610591900312, 1: 0.3578713968957871, 0: 0.23902439024390243}
Logged the results of 0% Pruning Rate to wandb!
/home/primmere/logs/pxp/results/2/1.0.pth
acc top1 (train) 0.3875
group accs (train) {2: 0.48, 0: 0.25, 3: 0.48, 1: 0.34}
Accuracy-Flow list (val): [0.34225060407317914, 0.3420780117362789]
Group accuracy (val): {3: 0.4766355140186916, 2: 0.514018691588785, 1: 0.3565410199556541, 0: 0.24035476718403548}
Logged the results of 0.01% Pruning Rate to wandb!
/home/primmere/logs/pxp/results/2/5.0.pth
acc top1 (train) 0.385
group accs (train) {0: 0.27, 1: 0.35, 2: 0.48, 3: 0.44}
Accuracy-Flow list (val): [0.34225060407317914, 0.3420780117362789, 0.34501208146358303]
Group accuracy (val): {3: 0.4797507788161994, 2: 0.5062305295950156, 1: 0.3631929046563193, 0: 0.24257206208425722}
Logged the results of 0.05% Pruning Rate to wandb!
/home/primmere/logs/pxp/results/2/10.0.pth
acc top1 (train) 0.3775
group accs (train) {3: 0.41, 2: 0.46, 1: 0.37, 0: 0.27}
Accuracy-Flow list (val): [0.34225060407317914, 0.3420780117362789, 0.34501208146358303, 0.35381429064549536]
Group accuracy (val): {3: 0.3894080996884735, 2: 0.5, 1: 0.4124168514412417, 0: 0.2434589800443459}
Logged the results of 0.1% Pruning Rate to wandb!
/home/primmere/logs/pxp/results/2/20.0.pth
acc top1 (train) 0.395
group accs (train) {3: 0.5, 2: 0.49, 0: 0.26, 1: 0.33}
Accuracy-Flow list (val): [0.34225060407317914, 0.3420780117362789, 0.34501208146358303, 0.35381429064549536, 0.34259578874697966]
Group accuracy (val): {3: 0.4423676012461059, 2: 0.514018691588785, 1: 0.3667405764966741, 0: 0.24124168514412417}
Logged the results of 0.2% Pruning Rate to wandb!
/home/primmere/logs/pxp/results/2/30.0.pth
acc top1 (train) 0.365
group accs (train) {2: 0.51, 1: 0.3, 3: 0.45, 0: 0.2}
Accuracy-Flow list (val): [0.34225060407317914, 0.3420780117362789, 0.34501208146358303, 0.35381429064549536, 0.34259578874697966, 0.32309285467725235]
Group accuracy (val): {3: 0.4236760124610592, 2: 0.5342679127725857, 1: 0.3450110864745011, 0: 0.21241685144124167}
Logged the results of 0.3% Pruning Rate to wandb!
/home/primmere/ide/external/pruning_by_explaining/my_experiments/my_global_pruning.py:309: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.
  top1_auc = np.trapz(top1_acc_list, pruning_rates)
Top1 AUC: 0.10273904038660682
Logged the AUC of the Top1 Accuracy to wandb!
Top1 AUC: 0.10273904038660682
