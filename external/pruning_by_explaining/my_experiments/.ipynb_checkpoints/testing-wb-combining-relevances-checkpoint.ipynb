{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79d284bb264d1f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:39:59.236365Z",
     "start_time": "2025-07-02T21:39:45.451882600Z"
    },
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import click\n",
    "import torch\n",
    "import tqdm.auto\n",
    "import numpy as np\n",
    "from torchvision.models import vit_b_16\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "#project_root = \"C:/Users/elmop/deep_feature_reweighting/deep_feature_reweighting/external/pruning_by_explaining\"\n",
    "project_root = \"/home/primmere/ide/external/pruning_by_explaining\"\n",
    "sys.path.insert(0, project_root)                 \n",
    "sys.path.insert(0, os.path.dirname(project_root))\n",
    "\n",
    "from pruning_by_explaining.models import ModelLoader\n",
    "from pruning_by_explaining.metrics import compute_accuracy\n",
    "from pruning_by_explaining.my_metrics import compute_worst_accuracy\n",
    "from pruning_by_explaining.my_datasets import WaterBirds, get_sample_indices_for_group, WaterBirdSubset, ISIC, ISICSubset\n",
    "from pruning_by_explaining.utils import (\n",
    "    initialize_random_seed,\n",
    "    initialize_wandb_logger,\n",
    ")\n",
    "\n",
    "\n",
    "from pruning_by_explaining.pxp import (\n",
    "    ModelLayerUtils,\n",
    "    get_cnn_composite,\n",
    "    get_vit_composite,\n",
    ")\n",
    "\n",
    "from pruning_by_explaining.pxp import GlobalPruningOperations\n",
    "from pruning_by_explaining.pxp import ComponentAttibution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4b96b7a-1da2-4d1e-96d9-9809ff76be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise(global_pruning_mask_combined, prune_r, layertype = \"Linear\"):\n",
    "    if layertype == \"Linear\":\n",
    "        count=0\n",
    "        ratios = np.zeros((12,2))\n",
    "        i = 0\n",
    "        for n, t in global_pruning_mask_combined.items():\n",
    "            param_total = t['Linear']['weight'].numel()\n",
    "            param_nonzero = t['Linear']['weight'].nonzero().size(0)\n",
    "            param_shape = t['Linear']['weight'].shape\n",
    "        \n",
    "            pruned = (param_total-param_nonzero)/param_shape[1]\n",
    "            total = param_total/param_shape[1]\n",
    "        \n",
    "            if 'mlp.0' in n:\n",
    "                ratios[i][0] = pruned/total\n",
    "            if 'mlp.3' in n:\n",
    "                ratios[i][1] = pruned/total\n",
    "                i += 1\n",
    "        \n",
    "        #print(array)\n",
    "        avgs = np.sum(ratios, axis=0)/12\n",
    "        \n",
    "        bar_width = 0.23\n",
    "        x = np.arange(12)\n",
    "        \n",
    "        labels = [\n",
    "            f\"fc1 r={avgs[0]:.4f}\",\n",
    "            f\"fc2 r={avgs[1]:.4f}\",\n",
    "        ]\n",
    "        offsets = (np.arange(ratios.shape[1]) - (ratios.shape[1] - 1) / 2) * bar_width\n",
    "        \n",
    "        for j, offset in enumerate(offsets):\n",
    "            plt.bar(x + offset, ratios[:, j], width=bar_width, label=labels[j])\n",
    "        \n",
    "        plt.xlabel(\"Transformer block idx\")\n",
    "        plt.ylabel(\"Prune ratio\")\n",
    "        plt.title(f'r = {prune_r}')\n",
    "        plt.xticks(x, [str(i) for i in range(12)])\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        save_dir = \"\"\n",
    "        save_path = os.path.join(save_dir, f\"prune_ratios{prune_r}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        #print(f\"Plot saved to {save_path}\")\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "    if layertype == \"Softmax\":\n",
    "        ratios = np.zeros((12,1))\n",
    "        i = 0\n",
    "        for v in global_pruning_mask_combined.values():\n",
    "            ratios[i][0] = len(v.detach().numpy())/12\n",
    "            i += 1\n",
    "\n",
    "        bar_width = 0.23\n",
    "        x = np.arange(12)\n",
    "        \n",
    "        labels = [\n",
    "            f\"Attention head\",\n",
    "        ]\n",
    "        offsets = (np.arange(ratios.shape[1]) - (ratios.shape[1] - 1) / 2) * bar_width\n",
    "        \n",
    "        for j, offset in enumerate(offsets):\n",
    "            plt.bar(x + offset, ratios[:, j], width=bar_width, label=labels[j])\n",
    "        \n",
    "        plt.xlabel(\"Transformer block idx\")\n",
    "        plt.ylabel(\"Prune ratio\")\n",
    "        plt.title(f'r = {prune_r}')\n",
    "        plt.xticks(x, [str(i) for i in range(12)])\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        save_dir = \"\"\n",
    "        save_path = os.path.join(save_dir, f\"prune_ratios{prune_r}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        #print(f\"Plot saved to {save_path}\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b41d0ce48cf8cb4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T08:24:20.023885700Z",
     "start_time": "2025-07-02T08:24:19.673321500Z"
    },
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "Number of unique labels: 2, Number of unique places: 2, Total groups: 4\n",
      "group 0: 3518\n",
      "group 1: 185\n",
      "group 2: 55\n",
      "group 3: 1037\n",
      "[0 1 2 3]\n",
      "Number of unique labels: 2, Number of unique places: 2, Total groups: 4\n",
      "group 0: 456\n",
      "group 1: 456\n",
      "group 2: 143\n",
      "group 3: 144\n",
      "[0 1 2 3]\n",
      "Number of unique labels: 2, Number of unique places: 2, Total groups: 4\n",
      "group 0: 2255\n",
      "group 1: 2255\n",
      "group 2: 642\n",
      "group 3: 642\n",
      "target groups: [0, 1, 2, 3]\n",
      "target groups: [1]\n",
      "target groups: [2]\n",
      "target groups: [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "initialize_random_seed(1)\n",
    "num_workers = 8\n",
    "device_string = \"cuda\"\n",
    "device = torch.device(device_string)\n",
    "waterbirds = WaterBirds('/scratch_shared/primmere/waterbird', seed = 1, num_workers = num_workers)\n",
    "least_rel_first = True\n",
    "abs_flag = True\n",
    "least_rel_first2 = False\n",
    "abs_flag2 = False\n",
    "Zplus_flag = True\n",
    "\n",
    "scale_bool = True\n",
    "\n",
    "prune_r = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "\n",
    "\n",
    "layer_type = 'Softmax'\n",
    "\n",
    "train_set = waterbirds.get_train_set()\n",
    "val_set = waterbirds.get_valid_set()\n",
    "test_set = waterbirds.get_test_set()\n",
    "\n",
    "pruning_indices = get_sample_indices_for_group(val_set, 30, device_string, [0,1,2,3])\n",
    "pruning_indices2 = get_sample_indices_for_group(val_set, 30, device_string, [1])\n",
    "pruning_indices3 = get_sample_indices_for_group(val_set, 30, device_string, [2])\n",
    "validation_indices = get_sample_indices_for_group(test_set, 'all', device_string)\n",
    "\n",
    "\n",
    "custom_pruning_set = WaterBirdSubset(val_set, pruning_indices)\n",
    "custom_pruning_set2 = WaterBirdSubset(val_set, pruning_indices2)\n",
    "custom_pruning_set3 = WaterBirdSubset(val_set, pruning_indices3)\n",
    "\n",
    "custom_val_set = WaterBirdSubset(test_set, validation_indices)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, num_workers=num_workers)\n",
    "prune_dataloader = torch.utils.data.DataLoader(custom_pruning_set, batch_size=8, shuffle=True, num_workers=num_workers)\n",
    "prune_dataloader2 = torch.utils.data.DataLoader(custom_pruning_set2, batch_size=8, shuffle=True, num_workers=num_workers)\n",
    "prune_dataloader3 = torch.utils.data.DataLoader(custom_pruning_set3, batch_size=8, shuffle=True, num_workers=num_workers)\n",
    "val_dataloader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672071d5bfd8ce01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:40:07.494175Z",
     "start_time": "2025-07-02T21:39:59.246373Z"
    },
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "suggested_composite = {\n",
    "        \"low_level_hidden_layer_rule\": \"Epsilon\",\n",
    "        \"mid_level_hidden_layer_rule\":\"Epsilon\",\n",
    "        \"high_level_hidden_layer_rule\": \"Epsilon\",\n",
    "        \"fully_connected_layers_rule\": \"Epsilon\",\n",
    "        \"softmax_rule\": \"Epsilon\",\n",
    "    }\n",
    "composite = get_vit_composite(\"vit_b_16\", suggested_composite)\n",
    "layer_types = {\n",
    "        \"Softmax\": torch.nn.Softmax,\n",
    "        \"Linear\": torch.nn.Linear,\n",
    "        \"Conv2d\": torch.nn.Conv2d,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de2053c4-6614-46aa-be9f-b59ef6189006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arch:vit_b_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/primmere/ide/external/pruning_by_explaining/models/utils.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arch:vit_b_16\n",
      "Arch:vit_b_16\n"
     ]
    }
   ],
   "source": [
    "model = ModelLoader.get_basic_model(\"vit_b_16\", \"/home/primmere/ide/dfr/logs/vit_waterbirds.pth\", device, num_classes=2)\n",
    "model2 = ModelLoader.get_basic_model(\"vit_b_16\", \"/home/primmere/ide/dfr/logs/vit_waterbirds.pth\", device, num_classes=2)\n",
    "model3 = ModelLoader.get_basic_model(\"vit_b_16\", \"/home/primmere/ide/dfr/logs/vit_waterbirds.pth\", device, num_classes=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20258526-a237-412b-957e-986133fc5f23",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0: 0.9937915742793791\\n1: 0.7835920177383592\\n2: 0.7461059190031153\\n3: 0.956386292834891\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "acc, acc_groups = compute_worst_accuracy(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        device,\n",
    "    )\n",
    "print(acc)\n",
    "for i in range(4):\n",
    "    print(f'{i}: {acc_groups[i]}')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "0: 0.9937915742793791\n",
    "1: 0.7835920177383592\n",
    "2: 0.7461059190031153\n",
    "3: 0.956386292834891\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad22e80f-eeb9-4057-9469-fbc18a92178b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nacc = compute_accuracy(\\n        model,\\n        val_dataloader,\\n        device,\\n    )\\nprint(acc)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "acc = compute_accuracy(\n",
    "        model,\n",
    "        val_dataloader,\n",
    "        device,\n",
    "    )\n",
    "print(acc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ef84cca0140e419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T08:41:21.019829100Z",
     "start_time": "2025-07-02T08:41:20.959062Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/primmere/.conda/envs/dfr2/lib/python3.10/site-packages/torch/autograd/graph.py:768: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "component_attributor = ComponentAttibution(\n",
    "        \"Relevance\",\n",
    "        \"ViT\",\n",
    "        layer_types[layer_type],\n",
    "        least_rel_first\n",
    "    )\n",
    "\n",
    "components_relevances = component_attributor.attribute(\n",
    "        model,\n",
    "        prune_dataloader,\n",
    "        composite,\n",
    "        abs_flag=abs_flag,\n",
    "        Zplus_flag=False,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "layer_names = component_attributor.layer_names\n",
    "pruner = GlobalPruningOperations(\n",
    "        layer_types[layer_type],\n",
    "        layer_names,\n",
    "    )\n",
    "\n",
    "global_pruning_mask = pruner.generate_global_pruning_mask(\n",
    "                model,\n",
    "                components_relevances,\n",
    "                0.1,\n",
    "                subsequent_layer_pruning=layer_type,\n",
    "                least_relevant_first=least_rel_first,\n",
    "                device=device,\n",
    "            )\n",
    "print(\"done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e2b6cd6-ab23-4f43-80f7-5b427c543e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hook_handles = pruner.fit_pruning_mask(model, global_pruning_mask,)\n",
    "#print(hook_handles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c48a67-6402-40b0-b4d0-682982946f0f",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "component_attributor2 = ComponentAttibution(\n",
    "        \"Relevance\",\n",
    "        \"ViT\",\n",
    "        layer_types[layer_type],\n",
    "        least_rel_first2\n",
    "    )\n",
    "\n",
    "components_relevances2 = component_attributor2.attribute(\n",
    "        model2,\n",
    "        prune_dataloader2,\n",
    "        composite,\n",
    "        abs_flag=abs_flag2,\n",
    "        Zplus_flag=Zplus_flag,\n",
    "        device=device,\n",
    "    )\n",
    "layer_names2 = component_attributor.layer_names\n",
    "pruner2 = GlobalPruningOperations(\n",
    "        layer_types[layer_type],\n",
    "        layer_names2,\n",
    "    )\n",
    "\n",
    "global_pruning_mask2 = pruner2.generate_global_pruning_mask(\n",
    "                model2,\n",
    "                components_relevances2,\n",
    "                0.1,\n",
    "                subsequent_layer_pruning=layer_type,\n",
    "                least_relevant_first=least_rel_first,\n",
    "                device=device,\n",
    "            )\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eb476ae-2a64-4201-9d7d-1182688e57df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "component_attributor3 = ComponentAttibution(\n",
    "        \"Relevance\",\n",
    "        \"ViT\",\n",
    "        layer_types[layer_type],\n",
    "        least_rel_first2\n",
    "    )\n",
    "\n",
    "components_relevances3 = component_attributor3.attribute(\n",
    "        model3,\n",
    "        prune_dataloader3,\n",
    "        composite,\n",
    "        abs_flag=abs_flag2,\n",
    "        Zplus_flag=Zplus_flag,\n",
    "        device=device,\n",
    "    )\n",
    "layer_names3 = component_attributor.layer_names\n",
    "pruner3 = GlobalPruningOperations(\n",
    "        layer_types[layer_type],\n",
    "        layer_names3,\n",
    "    )\n",
    "\n",
    "global_pruning_mask3 = pruner2.generate_global_pruning_mask(\n",
    "                model3,\n",
    "                components_relevances3,\n",
    "                0.1,\n",
    "                subsequent_layer_pruning=layer_type,\n",
    "                least_relevant_first=least_rel_first,\n",
    "                device=device,\n",
    "            )\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bee4756-02b2-4bd5-a4ed-e891ac93164b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hook_handles = pruner.fit_pruning_mask(model2, global_pruning_mask2,)\n",
    "#print(hook_handles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea6a59ca-654a-4b9d-bdeb-6d3409a82d7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"acc_worst, acc_groups = compute_worst_accuracy(\\n        model,\\n        val_dataloader,\\n        device,\\n    )\\nfor i in range(4):\\n    print(f'{i}: {acc_groups[i]}')\\n    \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"acc_worst, acc_groups = compute_worst_accuracy(\n",
    "        model,\n",
    "        val_dataloader,\n",
    "        device,\n",
    "    )\n",
    "for i in range(4):\n",
    "    print(f'{i}: {acc_groups[i]}')\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6748c5d1-a01c-45fb-81b1-3fd6b41bb814",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0: 0.9868421052631579\\n1: 0.7982456140350878\\n2: 0.7272727272727273\\n3: 0.9791666666666666\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "0: 0.9868421052631579\n",
    "1: 0.7982456140350878\n",
    "2: 0.7272727272727273\n",
    "3: 0.9791666666666666\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b272f-9475-4178-9147-ac499c22707e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2424feb9-7911-4016-a65e-dae746c8370f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nacc_worst, acc_groups = compute_worst_accuracy(\\n        model,\\n        val_dataloader,\\n        device,\\n    )\\nfor i in range(4):\\n    print(f'{i}: {acc_groups[i]}')\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "acc_worst, acc_groups = compute_worst_accuracy(\n",
    "        model,\n",
    "        val_dataloader,\n",
    "        device,\n",
    "    )\n",
    "for i in range(4):\n",
    "    print(f'{i}: {acc_groups[i]}')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5caa3dbf-889f-4ddc-ad09-10a166100f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nacc_worst, acc_groups = compute_worst_accuracy(\\n        model2,\\n        val_dataloader,\\n        device,\\n    )\\nfor i in range(4):\\n    print(f'{i}: {acc_groups[i]}')\\n\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "acc_worst, acc_groups = compute_worst_accuracy(\n",
    "        model2,\n",
    "        val_dataloader,\n",
    "        device,\n",
    "    )\n",
    "for i in range(4):\n",
    "    print(f'{i}: {acc_groups[i]}')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fed88fa9-7190-496b-a373-ea9bed479d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = len(pruning_indices)\n",
    "if scale_bool:\n",
    "    for t in components_relevances.values():\n",
    "        t.div_(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c26a9dba-5e60-4dde-9c51-bb0ef0c5d601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor k,v in components_relevances.items():\\n    if \"mlp.3\" in k:\\n        v.div_(4)\\n\\nfor k,v in components_relevances2.items():\\n    if \"mlp.3\" in k:\\n        v.div_(4)\\n\\nfor k,v in components_relevances3.items():\\n    if \"mlp.3\" in k:\\n        v.div_(4)\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for k,v in components_relevances.items():\n",
    "    if \"mlp.3\" in k:\n",
    "        v.div_(4)\n",
    "\n",
    "for k,v in components_relevances2.items():\n",
    "    if \"mlp.3\" in k:\n",
    "        v.div_(4)\n",
    "\n",
    "for k,v in components_relevances3.items():\n",
    "    if \"mlp.3\" in k:\n",
    "        v.div_(4)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d01b5393-d835-4548-8dd7-133ae3ee837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale2 = len(pruning_indices2)\n",
    "scale3 = len(pruning_indices3)\n",
    "if scale_bool :\n",
    "    for t in components_relevances2.values():\n",
    "        t.div_(scale2*2)\n",
    "    for t in components_relevances3.values():\n",
    "        t.div_(scale3*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a3490bb-3625-43c2-ba62-9869409af5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 30\n"
     ]
    }
   ],
   "source": [
    "print(scale, scale2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1462a03a-5bfc-4e37-849b-6a47322c98f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.055, 0.016, 0.018\n",
      "0.069, 0.015, 0.020\n",
      "0.111, 0.027, 0.027\n",
      "0.143, 0.030, 0.033\n",
      "0.154, 0.037, 0.037\n",
      "0.146, 0.035, 0.038\n",
      "0.162, 0.033, 0.037\n",
      "0.126, 0.027, 0.030\n",
      "0.140, 0.027, 0.033\n",
      "0.080, 0.016, 0.022\n",
      "0.054, 0.013, 0.013\n",
      "0.080, 0.013, 0.018\n"
     ]
    }
   ],
   "source": [
    "for k in components_relevances2.keys():\n",
    "    #print(torch.mean(v))\n",
    "    a = torch.mean(components_relevances[k]).item()\n",
    "    b = torch.mean(components_relevances2[k]).item()\n",
    "    c = torch.mean(components_relevances3[k]).item()\n",
    "    print(f'{a:.3f}, {b:.3f}, {c:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0d15975-f270-42b7-976f-388ade4b6ee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.layers.encoder_layer_0.self_attention.softmax 0.6642364263534546\n",
      "encoder.layers.encoder_layer_1.self_attention.softmax 0.833003044128418\n",
      "encoder.layers.encoder_layer_2.self_attention.softmax 1.3342777490615845\n",
      "encoder.layers.encoder_layer_3.self_attention.softmax 1.7167727947235107\n",
      "encoder.layers.encoder_layer_4.self_attention.softmax 1.8532968759536743\n",
      "encoder.layers.encoder_layer_5.self_attention.softmax 1.7472929954528809\n",
      "encoder.layers.encoder_layer_6.self_attention.softmax 1.9488774538040161\n",
      "encoder.layers.encoder_layer_7.self_attention.softmax 1.5074082612991333\n",
      "encoder.layers.encoder_layer_8.self_attention.softmax 1.6787011623382568\n",
      "encoder.layers.encoder_layer_9.self_attention.softmax 0.9655097723007202\n",
      "encoder.layers.encoder_layer_10.self_attention.softmax 0.6515893936157227\n",
      "encoder.layers.encoder_layer_11.self_attention.softmax 0.9574383497238159\n"
     ]
    }
   ],
   "source": [
    "for name, R in components_relevances.items():\n",
    "    print(name, torch.sum(R).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7e03dca-c95d-4829-9547-a86eb5e77fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncombined_relevances = {}\\nfor (k, v), (k2, v2) in zip(components_relevances.items(), components_relevances2.items()):\\n    combined_relevances[k] = v-v2\\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "combined_relevances = {}\n",
    "for (k, v), (k2, v2) in zip(components_relevances.items(), components_relevances2.items()):\n",
    "    combined_relevances[k] = v-v2\n",
    "\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9da8ce45-77f9-4149-80ef-57b2081a7f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "combined_relevances = {}\n",
    "check = True\n",
    "for (k1, v1), (k2, v2), (k3, v3) in zip(\n",
    "        components_relevances.items(), components_relevances2.items(), components_relevances3.items()\n",
    "):\n",
    "    check = check & (k1==k2==k3)\n",
    "    combined_relevances[k1] = v1 - v3\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b7e8d11-2cca-4d6c-9189-b7b8e6790fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "evaluating group acc:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 & 0.876 & 0.993 & 0.766 & 0.763 & 0.960 \\\\\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "evaluating group acc:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 & 0.875 & 0.993 & 0.766 & 0.760 & 0.958 \\\\\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "evaluating group acc:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 & 0.862 & 0.995 & 0.756 & 0.687 & 0.949 \\\\\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "evaluating group acc:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 & 0.849 & 0.992 & 0.706 & 0.737 & 0.956 \\\\\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "evaluating group acc:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 & 0.866 & 0.989 & 0.750 & 0.749 & 0.958 \\\\\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "evaluating group acc:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 & 0.876 & 0.991 & 0.805 & 0.654 & 0.945 \\\\\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "evaluating group acc:   0%|          | 0/46 [00:40<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 & 0.870 & 0.990 & 0.795 & 0.646 & 0.939 \\\\\n"
     ]
    }
   ],
   "source": [
    "for r in prune_r:\n",
    "    global_pruning_mask_combined = pruner.generate_global_pruning_mask(\n",
    "                    model,\n",
    "                    combined_relevances,\n",
    "                    r,\n",
    "                    subsequent_layer_pruning=layer_type,\n",
    "                    least_relevant_first=True,\n",
    "                    device=device,\n",
    "                )\n",
    "    hook_handles = pruner.fit_pruning_mask(model, global_pruning_mask_combined,)\n",
    "    acc, acc_groups = compute_worst_accuracy(\n",
    "            model,\n",
    "            val_dataloader,\n",
    "            device,\n",
    "        )\n",
    "    print(f'{r} & {acc:.3f} & {acc_groups[0]:.3f} & {acc_groups[1]:.3f} & {acc_groups[2]:.3f} & {acc_groups[3]:.3f} \\\\\\\\')\n",
    "    visualise(global_pruning_mask_combined, r, layer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17ab5090-9a65-449f-bee3-006f75e51c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_handles = pruner.fit_pruning_mask(model, global_pruning_mask_combined,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d76d864-9176-4345-bbab-1de27d1eae27",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n, t \u001b[38;5;129;01min\u001b[39;00m global_pruning_mask_combined\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 3\u001b[0m     param_total \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m      4\u001b[0m     param_nonzero \u001b[38;5;241m=\u001b[39m t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnonzero()\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m     param_shape \u001b[38;5;241m=\u001b[39m t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for n, t in global_pruning_mask_combined.items():\n",
    "    param_total = t['Linear']['weight'].numel()\n",
    "    param_nonzero = t['Linear']['weight'].nonzero().size(0)\n",
    "    param_shape = t['Linear']['weight'].shape\n",
    "    \n",
    "    pruned = (param_total-param_nonzero)/param_shape[1]\n",
    "    total = param_total/param_shape[1]\n",
    "    #print(pruned, \"/\", total, \"pruned,\", pruned/total)\n",
    "    print(f'{100*pruned/total:.1f}% - {pruned} / {total} pruned')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466eb15-f9a8-42be-a130-e8ddab627837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "acc, acc_groups = compute_worst_accuracy(\n",
    "        model,\n",
    "        val_dataloader,\n",
    "        device,\n",
    "    )\n",
    "print(acc)\n",
    "for i in range(4):\n",
    "    print(f'{i}: {acc_groups[i]}')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e782f2e2-8413-4517-b067-4a39819820a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#global_pruning_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cee3a74-6842-496a-ad4f-dd0887936387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#global_pruning_mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7409203-8aa2-436a-992b-806e956c814f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e814f7-1dac-462f-97e6-76e99dacbab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v, v2 in zip(components_relevances.values(), components_relevances2.values()):\n",
    "    print(v[0:8])\n",
    "    print(v2[0:8])\n",
    "    print(v[0:8]-v2[0:8])\n",
    "    print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf5e12-db0b-4891-add0-7354c7778bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{prune_r},{acc:.3f},{acc_groups[0]:.3f},{acc_groups[1]:.3f},{acc_groups[2]:.3f},{acc_groups[3]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d5e47-a302-4e68-b1c0-8ad2d03dde00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a40a04-c611-4c8a-bd89-0098caefae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{r} & {acc:.3f} & {acc_groups[0]:.3f} & {acc_groups[1]:.3f} & {acc_groups[2]:.3f} & {acc_groups[3]:.3f} \\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be818c92-7cba-4a7c-938e-6bdca6bd043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d7736-bfd2-4aba-bc8a-8196df3c5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise(global_pruning_mask_combined, r, layer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee831010-9350-40a2-b63e-e26d8f9d8293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfr2",
   "language": "python",
   "name": "dfr2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
