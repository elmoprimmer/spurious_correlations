{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-12T10:20:45.628817700Z",
     "start_time": "2024-09-12T10:20:36.346742500Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vit_b_16\n",
    "import torch\n",
    "\n",
    "import argparse\n",
    "\n",
    "from external.dfr.wb_data import WaterBirdsDataset, get_loader, get_transform_cub, log_data\n",
    "from external.dfr.utils import evaluate, get_y_p\n",
    "\n",
    "from external.dfr.wb_data import WaterBirdsDataset, get_loader, get_transform_cub, log_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T10:20:45.650352900Z",
     "start_time": "2024-09-12T10:20:45.631806300Z"
    }
   },
   "id": "9235fc13369662c2",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = vit_b_16(weights='DEFAULT')\n",
    "\n",
    "model.heads.head = nn.Linear(model.heads.head.in_features, NUM_CLASSES)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T10:20:46.676436600Z",
     "start_time": "2024-09-12T10:20:45.646344Z"
    }
   },
   "id": "dc9a14f6594c9ad6",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "VisionTransformer(\n  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n  (encoder): Encoder(\n    (dropout): Dropout(p=0.0, inplace=False)\n    (layers): Sequential(\n      (encoder_layer_0): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_1): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_2): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_3): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_4): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_5): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_6): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_7): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_8): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_9): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_10): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_11): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n  )\n  (heads): Sequential(\n    (head): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T10:20:46.695433500Z",
     "start_time": "2024-09-12T10:20:46.683433Z"
    }
   },
   "id": "e38aa178dabda7a3",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_token True\n",
      "conv_proj.weight True\n",
      "conv_proj.bias True\n",
      "encoder.pos_embedding True\n",
      "encoder.layers.encoder_layer_0.ln_1.weight True\n",
      "encoder.layers.encoder_layer_0.ln_1.bias True\n",
      "encoder.layers.encoder_layer_0.self_attention.in_proj_weight True\n",
      "encoder.layers.encoder_layer_0.self_attention.in_proj_bias True\n",
      "encoder.layers.encoder_layer_0.self_attention.out_proj.weight True\n",
      "encoder.layers.encoder_layer_0.self_attention.out_proj.bias True\n",
      "encoder.layers.encoder_layer_0.ln_2.weight True\n",
      "encoder.layers.encoder_layer_0.ln_2.bias True\n",
      "encoder.layers.encoder_layer_0.mlp.0.weight True\n",
      "encoder.layers.encoder_layer_0.mlp.0.bias True\n",
      "encoder.layers.encoder_layer_0.mlp.3.weight True\n",
      "encoder.layers.encoder_layer_0.mlp.3.bias True\n",
      "encoder.layers.encoder_layer_1.ln_1.weight True\n",
      "encoder.layers.encoder_layer_1.ln_1.bias True\n",
      "encoder.layers.encoder_layer_1.self_attention.in_proj_weight True\n",
      "encoder.layers.encoder_layer_1.self_attention.in_proj_bias True\n",
      "encoder.layers.encoder_layer_1.self_attention.out_proj.weight True\n",
      "encoder.layers.encoder_layer_1.self_attention.out_proj.bias True\n",
      "encoder.layers.encoder_layer_1.ln_2.weight True\n",
      "encoder.layers.encoder_layer_1.ln_2.bias True\n",
      "encoder.layers.encoder_layer_1.mlp.0.weight True\n",
      "encoder.layers.encoder_layer_1.mlp.0.bias True\n",
      "encoder.layers.encoder_layer_1.mlp.3.weight True\n",
      "encoder.layers.encoder_layer_1.mlp.3.bias True\n",
      "encoder.layers.encoder_layer_2.ln_1.weight True\n",
      "encoder.layers.encoder_layer_2.ln_1.bias True\n",
      "encoder.layers.encoder_layer_2.self_attention.in_proj_weight True\n",
      "encoder.layers.encoder_layer_2.self_attention.in_proj_bias True\n",
      "encoder.layers.encoder_layer_2.self_attention.out_proj.weight True\n",
      "encoder.layers.encoder_layer_2.self_attention.out_proj.bias True\n",
      "encoder.layers.encoder_layer_2.ln_2.weight True\n",
      "encoder.layers.encoder_layer_2.ln_2.bias True\n",
      "encoder.layers.encoder_layer_2.mlp.0.weight True\n",
      "encoder.layers.encoder_layer_2.mlp.0.bias True\n",
      "encoder.layers.encoder_layer_2.mlp.3.weight True\n",
      "encoder.layers.encoder_layer_2.mlp.3.bias True\n",
      "encoder.layers.encoder_layer_3.ln_1.weight True\n",
      "encoder.layers.encoder_layer_3.ln_1.bias True\n",
      "encoder.layers.encoder_layer_3.self_attention.in_proj_weight True\n",
      "encoder.layers.encoder_layer_3.self_attention.in_proj_bias True\n",
      "encoder.layers.encoder_layer_3.self_attention.out_proj.weight True\n",
      "encoder.layers.encoder_layer_3.self_attention.out_proj.bias True\n",
      "encoder.layers.encoder_layer_3.ln_2.weight True\n",
      "encoder.layers.encoder_layer_3.ln_2.bias True\n",
      "encoder.layers.encoder_layer_3.mlp.0.weight True\n",
      "encoder.layers.encoder_layer_3.mlp.0.bias True\n",
      "encoder.layers.encoder_layer_3.mlp.3.weight True\n",
      "encoder.layers.encoder_layer_3.mlp.3.bias True\n",
      "encoder.layers.encoder_layer_4.ln_1.weight True\n",
      "encoder.layers.encoder_layer_4.ln_1.bias True\n",
      "encoder.layers.encoder_layer_4.self_attention.in_proj_weight True\n",
      "encoder.layers.encoder_layer_4.self_attention.in_proj_bias True\n",
      "encoder.layers.encoder_layer_4.self_attention.out_proj.weight True\n",
      "encoder.layers.encoder_layer_4.self_attention.out_proj.bias True\n",
      "encoder.layers.encoder_layer_4.ln_2.weight True\n",
      "encoder.layers.encoder_layer_4.ln_2.bias True\n",
      "encoder.layers.encoder_layer_4.mlp.0.weight True\n",
      "encoder.layers.encoder_layer_4.mlp.0.bias True\n",
      "encoder.layers.encoder_layer_4.mlp.3.weight True\n",
      "encoder.layers.encoder_layer_4.mlp.3.bias True\n",
      "encoder.layers.encoder_layer_5.ln_1.weight True\n",
      "encoder.layers.encoder_layer_5.ln_1.bias True\n",
      "encoder.layers.encoder_layer_5.self_attention.in_proj_weight True\n",
      "encoder.layers.encoder_layer_5.self_attention.in_proj_bias True\n",
      "encoder.layers.encoder_layer_5.self_attention.out_proj.weight True\n",
      "encoder.layers.encoder_layer_5.self_attention.out_proj.bias True\n",
      "encoder.layers.encoder_layer_5.ln_2.weight True\n",
      "encoder.layers.encoder_layer_5.ln_2.bias True\n",
      "encoder.layers.encoder_layer_5.mlp.0.weight True\n",
      "encoder.layers.encoder_layer_5.mlp.0.bias True\n",
      "encoder.layers.encoder_layer_5.mlp.3.weight True\n",
      "encoder.layers.encoder_layer_5.mlp.3.bias True\n",
      "encoder.layers.encoder_layer_6.ln_1.weight True\n",
      "encoder.layers.encoder_layer_6.ln_1.bias True\n",
      "encoder.layers.encoder_layer_6.self_attention.in_proj_weight True\n",
      "encoder.layers.encoder_layer_6.self_attention.in_proj_bias True\n",
      "encoder.layers.encoder_layer_6.self_attention.out_proj.weight True\n",
      "encoder.layers.encoder_layer_6.self_attention.out_proj.bias True\n",
      "encoder.layers.encoder_layer_6.ln_2.weight True\n",
      "encoder.layers.encoder_layer_6.ln_2.bias True\n",
      "encoder.layers.encoder_layer_6.mlp.0.weight True\n",
      "encoder.layers.encoder_layer_6.mlp.0.bias True\n",
      "encoder.layers.encoder_layer_6.mlp.3.weight True\n",
      "encoder.layers.encoder_layer_6.mlp.3.bias True\n",
      "encoder.layers.encoder_layer_7.ln_1.weight True\n",
      "encoder.layers.encoder_layer_7.ln_1.bias True\n",
      "encoder.layers.encoder_layer_7.self_attention.in_proj_weight True\n",
      "encoder.layers.encoder_layer_7.self_attention.in_proj_bias True\n",
      "encoder.layers.encoder_layer_7.self_attention.out_proj.weight True\n",
      "encoder.layers.encoder_layer_7.self_attention.out_proj.bias True\n",
      "encoder.layers.encoder_layer_7.ln_2.weight True\n",
      "encoder.layers.encoder_layer_7.ln_2.bias True\n",
      "encoder.layers.encoder_layer_7.mlp.0.weight True\n",
      "encoder.layers.encoder_layer_7.mlp.0.bias True\n",
      "encoder.layers.encoder_layer_7.mlp.3.weight True\n",
      "encoder.layers.encoder_layer_7.mlp.3.bias True\n",
      "encoder.layers.encoder_layer_8.ln_1.weight True\n",
      "encoder.layers.encoder_layer_8.ln_1.bias True\n",
      "encoder.layers.encoder_layer_8.self_attention.in_proj_weight True\n",
      "encoder.layers.encoder_layer_8.self_attention.in_proj_bias True\n",
      "encoder.layers.encoder_layer_8.self_attention.out_proj.weight True\n",
      "encoder.layers.encoder_layer_8.self_attention.out_proj.bias True\n",
      "encoder.layers.encoder_layer_8.ln_2.weight True\n",
      "encoder.layers.encoder_layer_8.ln_2.bias True\n",
      "encoder.layers.encoder_layer_8.mlp.0.weight True\n",
      "encoder.layers.encoder_layer_8.mlp.0.bias True\n",
      "encoder.layers.encoder_layer_8.mlp.3.weight True\n",
      "encoder.layers.encoder_layer_8.mlp.3.bias True\n",
      "encoder.layers.encoder_layer_9.ln_1.weight True\n",
      "encoder.layers.encoder_layer_9.ln_1.bias True\n",
      "encoder.layers.encoder_layer_9.self_attention.in_proj_weight True\n",
      "encoder.layers.encoder_layer_9.self_attention.in_proj_bias True\n",
      "encoder.layers.encoder_layer_9.self_attention.out_proj.weight True\n",
      "encoder.layers.encoder_layer_9.self_attention.out_proj.bias True\n",
      "encoder.layers.encoder_layer_9.ln_2.weight True\n",
      "encoder.layers.encoder_layer_9.ln_2.bias True\n",
      "encoder.layers.encoder_layer_9.mlp.0.weight True\n",
      "encoder.layers.encoder_layer_9.mlp.0.bias True\n",
      "encoder.layers.encoder_layer_9.mlp.3.weight True\n",
      "encoder.layers.encoder_layer_9.mlp.3.bias True\n",
      "encoder.layers.encoder_layer_10.ln_1.weight True\n",
      "encoder.layers.encoder_layer_10.ln_1.bias True\n",
      "encoder.layers.encoder_layer_10.self_attention.in_proj_weight True\n",
      "encoder.layers.encoder_layer_10.self_attention.in_proj_bias True\n",
      "encoder.layers.encoder_layer_10.self_attention.out_proj.weight True\n",
      "encoder.layers.encoder_layer_10.self_attention.out_proj.bias True\n",
      "encoder.layers.encoder_layer_10.ln_2.weight True\n",
      "encoder.layers.encoder_layer_10.ln_2.bias True\n",
      "encoder.layers.encoder_layer_10.mlp.0.weight True\n",
      "encoder.layers.encoder_layer_10.mlp.0.bias True\n",
      "encoder.layers.encoder_layer_10.mlp.3.weight True\n",
      "encoder.layers.encoder_layer_10.mlp.3.bias True\n",
      "encoder.layers.encoder_layer_11.ln_1.weight True\n",
      "encoder.layers.encoder_layer_11.ln_1.bias True\n",
      "encoder.layers.encoder_layer_11.self_attention.in_proj_weight True\n",
      "encoder.layers.encoder_layer_11.self_attention.in_proj_bias True\n",
      "encoder.layers.encoder_layer_11.self_attention.out_proj.weight True\n",
      "encoder.layers.encoder_layer_11.self_attention.out_proj.bias True\n",
      "encoder.layers.encoder_layer_11.ln_2.weight True\n",
      "encoder.layers.encoder_layer_11.ln_2.bias True\n",
      "encoder.layers.encoder_layer_11.mlp.0.weight True\n",
      "encoder.layers.encoder_layer_11.mlp.0.bias True\n",
      "encoder.layers.encoder_layer_11.mlp.3.weight True\n",
      "encoder.layers.encoder_layer_11.mlp.3.bias True\n",
      "encoder.ln.weight True\n",
      "encoder.ln.bias True\n",
      "heads.head.weight True\n",
      "heads.head.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T10:20:46.734432800Z",
     "start_time": "2024-09-12T10:20:46.696442400Z"
    }
   },
   "id": "72c19055aade3a8c",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heads.head.weight: True\n",
      "heads.head.bias: True\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.heads.head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "#for name, module in model.named_modules():\n",
    "#    if \"mlp\" in name and isinstance(module, torch.nn.Linear):\n",
    "#        for param in module.parameters():\n",
    "#            param.requires_grad = True\n",
    "\n",
    " \n",
    "#for name, module in model.named_modules():\n",
    "#    if \"encoder.ln\" in name and isinstance(module, torch.nn.LayerNorm):\n",
    "#        for param in module.parameters():\n",
    "#            param.requires_grad = True\n",
    "            \n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "            print(f\"{name}: {param.requires_grad}\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T10:20:46.752439700Z",
     "start_time": "2024-09-12T10:20:46.728441300Z"
    }
   },
   "id": "c50e85dd6adc885e",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elmop\\AppData\\Local\\Temp\\ipykernel_2436\\694165624.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_orig.load_state_dict(torch.load(\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logs/vit_waterbirds.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m model_orig \u001B[38;5;241m=\u001B[39m vit_b_16(weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDEFAULT\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m model_orig\u001B[38;5;241m.\u001B[39mheads\u001B[38;5;241m.\u001B[39mhead \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(model_orig\u001B[38;5;241m.\u001B[39mheads\u001B[38;5;241m.\u001B[39mhead\u001B[38;5;241m.\u001B[39min_features, NUM_CLASSES)\n\u001B[1;32m----> 3\u001B[0m model_orig\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogs/vit_waterbirds.pth\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dfr\\lib\\site-packages\\torch\\serialization.py:1065\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1062\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m   1063\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m-> 1065\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m   1066\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[0;32m   1067\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[0;32m   1068\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[0;32m   1069\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[0;32m   1070\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dfr\\lib\\site-packages\\torch\\serialization.py:468\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    466\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    467\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 468\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    469\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    470\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dfr\\lib\\site-packages\\torch\\serialization.py:449\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 449\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'logs/vit_waterbirds.pth'"
     ]
    }
   ],
   "source": [
    "model_orig = vit_b_16(weights='DEFAULT')\n",
    "model_orig.heads.head = nn.Linear(model_orig.heads.head.in_features, NUM_CLASSES)\n",
    "model_orig.load_state_dict(torch.load(\n",
    "    \"logs/vit_waterbirds.pth\",map_location=torch.device('cpu')\n",
    "    ))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T10:20:49.232597400Z",
     "start_time": "2024-09-12T10:20:46.741435100Z"
    }
   },
   "id": "92ef9756d602692a",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model2 = vit_b_16(weights='DEFAULT')\n",
    "model2.heads.head = nn.Linear(model2.heads.head.in_features, NUM_CLASSES)\n",
    "model2.load_state_dict(torch.load(\n",
    "    \"logs/dfr_model.pth\",map_location=torch.device('cpu')\n",
    "    ))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T10:20:49.290590300Z",
     "start_time": "2024-09-12T10:20:49.236595100Z"
    }
   },
   "id": "128601bbf4396ffb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_average_weights(weights):\n",
    "    return np.mean(np.abs(weights), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.243600900Z"
    }
   },
   "id": "bc206b5d0ccdee91",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pre_weights = get_average_weights(model_orig.heads.head.weight.data.cpu().numpy()).reshape(24,32)\n",
    "post_weights = get_average_weights(model2.heads.head.weight.data.cpu().numpy()).reshape(24,32)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.247592200Z"
    }
   },
   "id": "7dc97747bcea994e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "get_average_weights(model_orig.heads.head.weight.data.cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.252595100Z"
    }
   },
   "id": "e51294055fa7befd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.256603Z"
    }
   },
   "id": "9f4da4ac32fd1b4a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.262595300Z"
    }
   },
   "id": "246f6a2a2dff22c6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "with open('logs/dfr_logreg.pth', 'rb') as file:\n",
    "    logreg = pickle.load(file)\n",
    "    \n",
    "logreg.coef_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.266606900Z"
    }
   },
   "id": "15ed4c76997f885e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.270600100Z"
    }
   },
   "id": "517a151cab17131",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logreg_weights = np.abs(logreg.coef_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.275593500Z"
    }
   },
   "id": "cfb7700b145f6ae8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_weight_grids(avg_before_reshaped, avg_after_reshaped, cmap='CMRmap',title1 = \"vit_waterbird\", title2 = \"dfr\"):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    vmin = min(avg_before_reshaped.min(), avg_after_reshaped.min())\n",
    "    vmax = min(avg_before_reshaped.max(), avg_after_reshaped.max())##set to max to change colour scale\n",
    "\n",
    "    im1 = axes[0].imshow(avg_before_reshaped, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
    "    axes[0].set_title(title1)\n",
    "    axes[0].set_xlabel('')\n",
    "    axes[0].set_ylabel('')\n",
    "    plt.colorbar(im1, ax=axes[0])\n",
    "    \n",
    "    im2 = axes[1].imshow(avg_after_reshaped, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
    "    axes[1].set_title(title2)\n",
    "    axes[1].set_xlabel('')\n",
    "    axes[1].set_ylabel('')\n",
    "    plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.279604500Z"
    }
   },
   "id": "9694f4cd4aa38226",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.282591700Z"
    }
   },
   "id": "93bc68b39224af46",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**last layer retrained**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8069d8457391122"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_weight_grids(pre_weights, post_weights, title2=\"dfr_last_layer_retrained\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.284591300Z"
    }
   },
   "id": "a6c57905088b401f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**logreg**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29a4b76fe040655a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_weight_grids(pre_weights, logreg_weights.reshape(24,32), title2=\"dfr_last_layer_logreg\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.286591900Z"
    }
   },
   "id": "a68d83ae4b836963",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "nr_pre = scaler.fit_transform(pre_weights)\n",
    "nr_post = scaler.fit_transform(post_weights)\n",
    "nr_logreg = scaler.fit_transform(logreg_weights.reshape(24,32))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.289591600Z"
    }
   },
   "id": "ed1cd678353a679b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Normalised**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7bf2f9fb705ad24"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_weight_grids(nr_logreg, nr_post, title1=\"nr_logreg\", title2=\"nr_dfr_finetune\") ## testing how they look normalised\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T10:20:49.295593900Z",
     "start_time": "2024-09-12T10:20:49.292595800Z"
    }
   },
   "id": "3608e2d99f7d258a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.max(nr_post)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.294598700Z"
    }
   },
   "id": "f727002972abf169",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model2.heads.head.weight.data.cpu().numpy().shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-12T10:20:49.310592600Z",
     "start_time": "2024-09-12T10:20:49.297593800Z"
    }
   },
   "id": "f379279e4052ad0b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "one = np.abs(model2.heads.head.weight.data.cpu().numpy()[0,:]).reshape(24,32)\n",
    "two = np.abs(model2.heads.head.weight.data.cpu().numpy()[1,:]).reshape(24,32)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.300602600Z"
    }
   },
   "id": "afec7dd1351d5ff6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**W1 vs W2**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "417d7d56547d1f35"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_weight_grids(one, two)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.303600900Z"
    }
   },
   "id": "542fddb47b5e7b4a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-12T10:20:49.306596100Z"
    }
   },
   "id": "3d4628ad11e43888"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
