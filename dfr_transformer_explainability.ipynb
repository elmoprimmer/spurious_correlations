{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-15T14:38:09.402135200Z",
     "start_time": "2024-10-15T14:38:09.388572300Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "from torchvision.models import vit_b_16\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from surgeon_pytorch import Extract, get_nodes\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from captum.attr import LayerGradCam, LayerAttribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "external_repo_path = os.path.abspath('external/transformer_explainability')\n",
    "if external_repo_path not in sys.path:\n",
    "    sys.path.append(external_repo_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T14:38:15.850634700Z",
     "start_time": "2024-10-15T14:38:15.845617900Z"
    }
   },
   "id": "c9a4fea11731370f",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = vit_b_16()\n",
    "model.heads.head = nn.Linear(768,2)\n",
    "model.load_state_dict(torch.load(\"logs/dfr_model.pth\", map_location=torch.device('cpu'), weights_only=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:37:51.467276200Z",
     "start_time": "2024-10-15T13:37:49.854905300Z"
    }
   },
   "id": "da56c58741cc1cb6",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_224-80ecf9dd.pth\" to C:\\Users\\elmop/.cache\\torch\\hub\\checkpoints\\jx_vit_base_p16_224-80ecf9dd.pth\n"
     ]
    }
   ],
   "source": [
    "from external.transformer_explainability.baselines.ViT.ViT_LRP import vit_base_patch16_224 as vit_LRP\n",
    "from external.transformer_explainability.baselines.ViT.ViT_explanation_generator import LRP\n",
    "\n",
    "model2 = vit_LRP(pretrained=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T14:38:49.183598800Z",
     "start_time": "2024-10-15T14:38:24.259784Z"
    }
   },
   "id": "93eee2dd3f378bc5",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "attribution_generator = LRP(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T14:46:30.657839700Z",
     "start_time": "2024-10-15T14:46:30.621828400Z"
    }
   },
   "id": "12c46ce76400dd60",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def tensorize(img_path):\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    return preprocess(image).unsqueeze(0)\n",
    "\n",
    "\n",
    "def show_cam_on_image(img, mask):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = heatmap + np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    return cam\n",
    "\n",
    "def generate_visualization(original_image, class_index=None):\n",
    "    transformer_attribution = attribution_generator.generate_LRP(original_image.unsqueeze(0).cuda(), method=\"transformer_attribution\", index=class_index).detach()\n",
    "    transformer_attribution = transformer_attribution.reshape(1, 1, 14, 14)\n",
    "    transformer_attribution = torch.nn.functional.interpolate(transformer_attribution, scale_factor=16, mode='bilinear')\n",
    "    transformer_attribution = transformer_attribution.reshape(224, 224).data.cpu().numpy()\n",
    "    transformer_attribution = (transformer_attribution - transformer_attribution.min()) / (transformer_attribution.max() - transformer_attribution.min())\n",
    "\n",
    "\n",
    "\n",
    "    image_transformer_attribution = original_image.permute(1, 2, 0).data.cpu().numpy()\n",
    "    image_transformer_attribution = (image_transformer_attribution - image_transformer_attribution.min()) / (image_transformer_attribution.max() - image_transformer_attribution.min())\n",
    "    vis = show_cam_on_image(image_transformer_attribution, transformer_attribution)\n",
    "    vis =  np.uint8(255 * vis)\n",
    "    vis = cv2.cvtColor(np.array(vis), cv2.COLOR_RGB2BGR)\n",
    "    return vis"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T14:51:12.584439900Z",
     "start_time": "2024-10-15T14:51:12.556448900Z"
    }
   },
   "id": "6c47c4958873da5d",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 224, 224])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tensorize('notebooks/data/001.Black_footed_Albatross/Black_Footed_Albatross_0001_796111.jpg')\n",
    "img.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T14:49:03.484538700Z",
     "start_time": "2024-10-15T14:49:03.455945700Z"
    }
   },
   "id": "1bdb422d6185fba1",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "out = model(img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T14:50:16.681559900Z",
     "start_time": "2024-10-15T14:50:10.301037Z"
    }
   },
   "id": "882b93602764686f",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mgenerate_visualization\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[22], line 20\u001B[0m, in \u001B[0;36mgenerate_visualization\u001B[1;34m(original_image, class_index)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_visualization\u001B[39m(original_image, class_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m---> 20\u001B[0m     transformer_attribution \u001B[38;5;241m=\u001B[39m \u001B[43mattribution_generator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_LRP\u001B[49m\u001B[43m(\u001B[49m\u001B[43moriginal_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m                                                                 \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtransformer_attribution\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m                                                                 \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_index\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdetach()\n\u001B[0;32m     23\u001B[0m     transformer_attribution \u001B[38;5;241m=\u001B[39m transformer_attribution\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m14\u001B[39m, \u001B[38;5;241m14\u001B[39m)\n\u001B[0;32m     24\u001B[0m     transformer_attribution \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39minterpolate(transformer_attribution, scale_factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbilinear\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\deep_feature_reweighting\\deep_feature_reweighting\\external\\transformer_explainability\\baselines\\ViT\\ViT_explanation_generator.py:35\u001B[0m, in \u001B[0;36mLRP.generate_LRP\u001B[1;34m(self, input, index, method, is_ablation, start_layer)\u001B[0m\n\u001B[0;32m     33\u001B[0m one_hot_vector \u001B[38;5;241m=\u001B[39m one_hot\n\u001B[0;32m     34\u001B[0m one_hot \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(one_hot)\u001B[38;5;241m.\u001B[39mrequires_grad_(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 35\u001B[0m one_hot \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(\u001B[43mone_hot\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m output)\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     38\u001B[0m one_hot\u001B[38;5;241m.\u001B[39mbackward(retain_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dfr\\lib\\site-packages\\torch\\cuda\\__init__.py:305\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    300\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    301\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    302\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    303\u001B[0m     )\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    306\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    307\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    309\u001B[0m     )\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "generate_visualization(img,0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T14:51:23.949463200Z",
     "start_time": "2024-10-15T14:51:22.555403100Z"
    }
   },
   "id": "d99fd2646223a426",
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
